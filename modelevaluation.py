# -*- coding: utf-8 -*-
"""ModelEvaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JmLDQuH-xkXgANFw7tqFIJrishA_m1up
"""



"""# Task
Train multiple machine learning models on the Wine dataset from scikit-learn, perform hyperparameter tuning using GridSearchCV and RandomizedSearchCV, evaluate their performance using accuracy, precision, recall, and F1-score, and select the best-performing model.

## Load data

### Subtask:
Load the Wine dataset from scikit-learn.

**Reasoning**:
Import the `load_wine` function, load the dataset, and print its keys to understand its structure.
"""

from sklearn.datasets import load_wine

wine_data = load_wine()
print(wine_data.keys())

"""## Split data

### Subtask:
Split the dataset into training and testing sets.

**Reasoning**:
Split the data into training and testing sets and print their shapes.
"""

from sklearn.model_selection import train_test_split

X = wine_data.data
y = wine_data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Define models

### Subtask:
Define multiple machine learning models to be evaluated.

**Reasoning**:
Import the necessary model classes and instantiate them with default parameters, then store them in a dictionary.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

models = {
    'LogisticRegression': LogisticRegression(),
    'SVC': SVC(),
    'DecisionTreeClassifier': DecisionTreeClassifier(),
    'KNeighborsClassifier': KNeighborsClassifier()
}

print("Defined models:")
for name, model in models.items():
    print(f"- {name}: {model}")

"""## Hyperparameter tuning

### Subtask:
Implement hyperparameter tuning using GridSearchCV and RandomizedSearchCV for each model.

**Reasoning**:
Implement hyperparameter tuning for each model using GridSearchCV and RandomizedSearchCV, fit the search objects to the training data, and store the best parameters.
"""

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
import numpy as np

param_grids = {
    'LogisticRegression': {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear']
    },
    'SVC': {
        'C': [0.1, 1, 10],
        'gamma': [1, 0.1, 0.01],
        'kernel': ['rbf', 'linear']
    },
    'DecisionTreeClassifier': {
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'KNeighborsClassifier': {
        'n_neighbors': np.arange(1, 21),
        'weights': ['uniform', 'distance']
    }
}

best_params = {}

for name, model in models.items():
    if name == 'LogisticRegression':
        search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')
    elif name == 'SVC':
         search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')
    elif name == 'DecisionTreeClassifier':
        search = RandomizedSearchCV(model, param_grids[name], n_iter=20, cv=5, scoring='accuracy', random_state=42)
    elif name == 'KNeighborsClassifier':
         search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy')

    search.fit(X_train, y_train)
    best_params[name] = search.best_params_
    print(f"Best parameters for {name}: {best_params[name]}")

"""## Train and evaluate

### Subtask:
Train each model with the tuned hyperparameters and evaluate their performance using accuracy, precision, recall, and F1-score on the test set.

**Reasoning**:
Train each model with the tuned hyperparameters and evaluate their performance using accuracy, precision, recall, and F1-score on the test set.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

evaluation_results = {}

for name, model in models.items():
    tuned_model = model.__class__(**best_params[name])
    tuned_model.fit(X_train, y_train)
    y_pred = tuned_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    evaluation_results[name] = {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1
    }

    print(f"--- {name} ---")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")

"""## Analyze results

### Subtask:
Analyze the evaluation results and select the best-performing model.

**Reasoning**:
Analyze the evaluation results to identify the best performing model based on the provided metrics.
"""

import pandas as pd

evaluation_df = pd.DataFrame(evaluation_results)
display(evaluation_df)

best_model_name = None
best_f1_score = -1

for model_name, metrics in evaluation_results.items():
    if metrics['f1_score'] > best_f1_score:
        best_f1_score = metrics['f1_score']
        best_model_name = model_name

print(f"\nThe best performing model based on F1-score is: {best_model_name}")

"""## Summary:

### Data Analysis Key Findings

*   The Wine dataset was successfully loaded and split into training and testing sets (80/20 split).
*   Four different machine learning models were defined for evaluation: Logistic Regression, Support Vector Classifier (SVC), Decision Tree Classifier, and K Neighbors Classifier.
*   Hyperparameter tuning was performed using GridSearchCV for Logistic Regression, SVC, and K Neighbors Classifier, and RandomizedSearchCV for Decision Tree Classifier.
*   After tuning and training, the models were evaluated on the test set using accuracy, precision, recall, and F1-score.
*   The SVC model achieved the highest performance across all metrics on the test set, with an accuracy, precision, recall, and F1-score of 1.0000.
*   The K Neighbors Classifier had the lowest performance among the evaluated models.
*   Based on the F1-score, the best-performing model was identified as SVC.


"""